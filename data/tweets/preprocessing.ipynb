{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('covid_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sg/4x_5htrx3y7fm7z77wcz8c_40000gn/T/ipykernel_49760/2874991781.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data = data.astype(str).str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data):\n",
    "    #Removes Numbers\n",
    "    data = data.astype(str).str.replace('\\d+', '')\n",
    "    lower_text = data.str.lower()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    w_tokenizer =  TweetTokenizer()\n",
    "    def lemmatize_text(text):\n",
    "        return [(lemmatizer.lemmatize(w)) for w \\\n",
    "                       in w_tokenizer.tokenize((text))]\n",
    "    def remove_punctuation(words):\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', (word))\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "        return new_words\n",
    "    words = lower_text.apply(lemmatize_text)\n",
    "    words = words.apply(remove_punctuation)\n",
    "    return pd.DataFrame(words)\n",
    "\n",
    "pre_tweets = preprocess_data(tweets['tweet'])\n",
    "tweets['tweet'] = pre_tweets\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tweets['tweet'] = tweets['tweet'].apply(lambda x: ' '.join([item for item in \\\n",
    "                                    x if item not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid denier website next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scotland ha people hospital covid point pandem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>want pandemic end trying away arent helping u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world health organization say new covid xe var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid vaccine unvaccinated aggressively threat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>billion waste mountain junk ppe bought tory cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>swedens twitter account covid stats hasnt upda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>see exact sht went last year grammys people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>unemployment nation wa rising covid result gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>relative mine going hospital test friday admit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet\n",
       "0                             covid denier website next\n",
       "1     scotland ha people hospital covid point pandem...\n",
       "2     want pandemic end trying away arent helping u ...\n",
       "3     world health organization say new covid xe var...\n",
       "4     covid vaccine unvaccinated aggressively threat...\n",
       "...                                                 ...\n",
       "1995  billion waste mountain junk ppe bought tory cr...\n",
       "1996  swedens twitter account covid stats hasnt upda...\n",
       "1997        see exact sht went last year grammys people\n",
       "1998  unemployment nation wa rising covid result gro...\n",
       "1999  relative mine going hospital test friday admit...\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('covid_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "credentials = json.load(open('credentials.json'))\n",
    "\n",
    "consumer_key = credentials['consumer_key']\n",
    "consumer_secret = credentials['consumer_secret']\n",
    "access_token = credentials['access_token']\n",
    "access_token_secret = credentials['access_token_secret']\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweets(searchTerm):\n",
    "    n = 1000\n",
    "    tweets = tweepy.Cursor(api.search_tweets,q=searchTerm,lang=\"en\",tweet_mode=\"extended\").items(n)\n",
    "    tweets_json=[]\n",
    "    for tweet in tweets:\n",
    "        tweets_json.append(tweet._json)\n",
    "    return tweets_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covid_tweets = search_tweets('covid')\n",
    "omicron_tweets = search_tweets('omicron')\n",
    "# world_economy_tweets = search_tweets('world economy')\n",
    "# remittance_tweets = search_tweets('remittance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_to_csv(tweets_json, name='covid'):\n",
    "    tweets = [tweet['full_text'] for tweet in tweets_json]\n",
    "    tweet_df = pd.DataFrame({'tweet': tweets})\n",
    "    tweet_df['tweet'] = tweet_df['tweet'].apply(p.clean)\n",
    "    tweet_df.to_csv(f'{name}_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_to_csv(covid_tweets, 'covid')\n",
    "tweets_to_csv(omicron_tweets, 'omicron')\n",
    "# tweets_to_csv(world_economy_tweets, 'world_economy')\n",
    "# tweets_to_csv(remittance_tweets, 'remittance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/4x_5htrx3y7fm7z77wcz8c_40000gn/T/ipykernel_39144/1690482181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcovid_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_json'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "covid_tweets['_json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6cba64f92086cea4f7c8f7f244f42e1e8cb9624a24fb73ff9c983ad8555d3f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('multitask-bert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
